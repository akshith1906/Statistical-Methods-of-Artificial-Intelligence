{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ed502e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50) uint8\n",
      "Number of 1s in the mask: 1986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ORANGE_BGR = np.array([  0, 165, 255], dtype=np.float32)  # Netherlands - 1\n",
    "PURPLE_BGR = np.array([128,   0, 128], dtype=np.float32)  # Belgium     - 0\n",
    "\n",
    "def binary_mask_50x50_cv2(path):\n",
    "\n",
    "    # Reads a 50x50 image and returns a mask of {0,1}.\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)          \n",
    "    arr = img.astype(np.float32)\n",
    "\n",
    "    d_orange = np.linalg.norm(arr - ORANGE_BGR, axis=-1)\n",
    "    d_purple = np.linalg.norm(arr - PURPLE_BGR, axis=-1)\n",
    "\n",
    "    mask = (d_orange < d_purple).astype(np.uint8)      \n",
    "    return mask\n",
    "\n",
    "mask = binary_mask_50x50_cv2(\"Q1\\\\border.png\")\n",
    "print(mask.shape, mask.dtype)  # (50, 50) uint8\n",
    "\n",
    "#print number of 1s in the mask\n",
    "print(\"Number of 1s in the mask:\", np.sum(mask))  # Number of 1s in the mask: 1250\n",
    "\n",
    "# Saving the mask as an image\n",
    "cv2.imwrite(\"output\\\\binary_mask_50x50.png\", mask * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5ed639f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples(mask):\n",
    "\n",
    "    h, w = mask.shape\n",
    "    samples = []\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            samples.append([\n",
    "                x / (w - 1),\n",
    "                y / (h - 1),\n",
    "                float(mask[y, x])\n",
    "            ])\n",
    "\n",
    "    samples = np.array(samples, dtype=np.float32)\n",
    "\n",
    "    np.random.shuffle(samples)\n",
    "\n",
    "\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1a021f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (2500, 3)\n",
      "First 5 samples (xy, L): [(array([0.14285715, 0.1632653 ], dtype=float32), 1.0), (array([0.6122449, 0.6938776], dtype=float32), 0.0), (array([0.20408164, 0.63265306], dtype=float32), 1.0), (array([0.59183675, 0.67346936], dtype=float32), 1.0), (array([0.67346936, 0.48979592], dtype=float32), 1.0)]\n"
     ]
    }
   ],
   "source": [
    "samples = make_samples(mask)  # (2500, 3)\n",
    "print(\"samples shape:\", samples.shape)  \n",
    "xy = samples[:, :2]\n",
    "L  = samples[:,  2]\n",
    "pairs = [ (xy_i, L_i) for xy_i, L_i in zip(xy, L) ]\n",
    "print(\"First 5 samples (xy, L):\", pairs[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5dcc8",
   "metadata": {},
   "source": [
    "mlp_scratch \n",
    "\n",
    "  -> __init__.py \n",
    "\n",
    "  -> activations.py\n",
    "\n",
    "  -> layers.py\n",
    "\n",
    "  -> losses.py\n",
    "\n",
    "  -> model.py\n",
    "\n",
    "  -> train.py\n",
    "\n",
    "  -> utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2b0ca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_scratch.activations import ReLU, Tanh, Sigmoid, Identity\n",
    "from mlp_scratch.layers import Linear\n",
    "from mlp_scratch.model import Model\n",
    "from mlp_scratch.train import train\n",
    "from mlp_scratch.utils import binary_accuracy, ensure_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9e9cbfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]], dtype=float32),\n",
       " array([0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_xor_dataset():\n",
    "    X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1],\n",
    "                  [0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]], dtype=np.float32)\n",
    "    Y = np.array([0, 1, 1, 0, 0, 1, 1, 0], dtype=np.float32)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = make_xor_dataset()\n",
    "X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6f043d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 3000/3000 [00:00<00:00, 5791.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained ypred: [0.15062733 0.89969474 0.93072987 0.08199544 0.15062733 0.89969474\n",
      " 0.93072987 0.08199544]\n",
      "trained acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "def he_scale(fan_in):\n",
    "    return float(np.sqrt(2.0 / max(1, fan_in)))\n",
    "\n",
    "def xavier_scale(fan_in):\n",
    "    return float(np.sqrt(1.0 / max(1, fan_in)))\n",
    "\n",
    "def build_relu_model_2_2_1(lr=2e-2, relu_bias=0.1):\n",
    "    L1 = Linear(2, 4, ReLU(),    scale=he_scale(2))   # ReLU hidden\n",
    "    L1.b[:] = relu_bias\n",
    "    L2 = Linear(4, 1, Sigmoid(), scale=xavier_scale(2)) # Sigmoid head\n",
    "    return Model([L1, L2], loss=\"bce\", lr=lr)\n",
    "\n",
    "model = build_relu_model_2_2_1(lr=2e-2, relu_bias=0.1)\n",
    "meta, _ = train(\n",
    "    model, X, Y,\n",
    "    batch_size=4,\n",
    "    grad_accum_steps=1,\n",
    "    max_epochs=3000,\n",
    "    patience=300,\n",
    "    rel_improve_thresh=1e-3,\n",
    "    runs_dir=\"runs_xor\",\n",
    "    run_name=\"xor_relu_trained\",\n",
    "    seed=None,\n",
    ")\n",
    "\n",
    "yp = model.predict(X)\n",
    "print(\"trained ypred:\", yp.ravel())\n",
    "print(\"trained acc:\", binary_accuracy(yp, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check(model, X, Y, eps=1e-5, tol=1e-3):\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    # scalar loss on current params using full batch\n",
    "    def _loss():\n",
    "        yp = model.predict(X)\n",
    "        y = Y[:, None] if Y.ndim == 1 else Y\n",
    "        return model.loss_fn.forward(yp, y)\n",
    "\n",
    "    # numerical grads\n",
    "    num_W, num_b = [], []\n",
    "    for L in model.layers:\n",
    "        dW = np.zeros_like(L.W, dtype=np.float32)\n",
    "        db = np.zeros_like(L.b, dtype=np.float32)\n",
    "        for idx in np.ndindex(*L.W.shape):\n",
    "            old = L.W[idx]\n",
    "            L.W[idx] = old + eps; Lp = _loss()\n",
    "            L.W[idx] = old - eps; Lm = _loss()\n",
    "            L.W[idx] = old\n",
    "            dW[idx] = (Lp - Lm) / (2*eps)\n",
    "        for j in np.ndindex(*L.b.shape):\n",
    "            old = L.b[j]\n",
    "            L.b[j] = old + eps; Lp = _loss()\n",
    "            L.b[j] = old - eps; Lm = _loss()\n",
    "            L.b[j] = old\n",
    "            db[j] = (Lp - Lm) / (2*eps)\n",
    "        num_W.append(dW); num_b.append(db)\n",
    "\n",
    "    # backprop grads (one full-batch step)\n",
    "    for L in model.layers: L.zero_grad()\n",
    "    model.train_step(X, Y)  # fills L.dW_acc / L.db_acc\n",
    "    bp_W = [L.dW_acc.copy() for L in model.layers]\n",
    "    bp_b = [L.db_acc.copy() for L in model.layers]\n",
    "\n",
    "    # relative error\n",
    "    def rel_err(a, b):\n",
    "        import numpy as np\n",
    "        na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "        return float(np.linalg.norm(a - b) / max(1e-12, na + nb))\n",
    "\n",
    "    passed = True\n",
    "    for i, (nW, nB, aW, aB) in enumerate(zip(num_W, num_b, bp_W, bp_b)):\n",
    "        eW, eB = rel_err(nW, aW), rel_err(nB, aB)\n",
    "        print(f\"layer {i}: W_err={eW:.3e}  b_err={eB:.3e}\")\n",
    "        passed &= (eW < tol) and (eB < tol)\n",
    "\n",
    "    return passed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "774a5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: W_err=7.768e-01  b_err=7.775e-01\n",
      "layer 1: W_err=7.776e-01  b_err=7.715e-01\n",
      "\n",
      "-- eps=0.0001 --\n",
      "layer 0: W_err=7.780e-01  b_err=7.780e-01\n",
      "layer 1: W_err=7.773e-01  b_err=7.782e-01\n",
      "\n",
      "-- eps=1e-05 --\n",
      "layer 0: W_err=7.768e-01  b_err=7.775e-01\n",
      "layer 1: W_err=7.776e-01  b_err=7.715e-01\n",
      "\n",
      "-- eps=1e-06 --\n",
      "layer 0: W_err=8.040e-01  b_err=8.288e-01\n",
      "layer 1: W_err=7.265e-01  b_err=5.817e-01\n"
     ]
    }
   ],
   "source": [
    "# run once\n",
    "grad_check(model, X, Y, eps=1e-5, tol=1e-3)\n",
    "\n",
    "for eps in (1e-4, 1e-5, 1e-6):\n",
    "    print(f\"\\n-- eps={eps} --\")\n",
    "    grad_check(model, X, Y, eps=eps, tol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e95c6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xy.astype(np.float32)          # (2500, 2) normalized coords\n",
    "Y = L.astype(np.float32)           # (2500,)   labels {0,1}\n",
    "h, w = mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3b95869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  81%|████████▏ | 2438/3000 [12:44<02:56,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map accuracy: 0.7944\n",
      "GT prior: 0.7944 Pred prior: 1.0\n",
      "Loss plot: runs_map\\relu_64x2_plain_bce\\loss_vs_samples.png\n"
     ]
    }
   ],
   "source": [
    "def he(f): return float(np.sqrt(2.0/max(1,f)))\n",
    "def xv(f): return float(np.sqrt(1.0/max(1,f)))\n",
    "\n",
    "def build_model(hidden=(64,64), lr=5e-3, relu_bias=0.1):\n",
    "    layers = []\n",
    "    in_dim = 2\n",
    "    for hsz in hidden:\n",
    "        L = Linear(in_dim, hsz, Tanh(), scale=he(in_dim))\n",
    "        L.b[:] = relu_bias\n",
    "        layers.append(L)\n",
    "        in_dim = hsz\n",
    "    layers.append(Linear(in_dim, 1, Tanh(), scale=xv(in_dim)))\n",
    "    return Model(layers, loss=\"bce\", lr=lr)   # <-- plain BCE\n",
    "\n",
    "# build model (no BalancedBCELoss)\n",
    "model = build_model(hidden=(1000,1000), lr=5e-3, relu_bias=0.1)\n",
    "\n",
    "# optional: good init for the sigmoid head\n",
    "p = float(mask.mean())\n",
    "model.layers[-1].b[:] = np.float32(np.log(p/(1.0 - p)))\n",
    "\n",
    "meta, _ = train(\n",
    "    model, X, Y,\n",
    "    batch_size=256,\n",
    "    grad_accum_steps=2,\n",
    "    max_epochs=3000,\n",
    "    patience=100,\n",
    "    rel_improve_thresh=0.002,\n",
    "    runs_dir=\"runs_map\",\n",
    "    run_name=\"relu_64x2_plain_bce\",\n",
    "    seed=None,\n",
    ")\n",
    "\n",
    "# predict full image + metrics\n",
    "yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing=\"ij\")\n",
    "Xfull = np.stack([(xx/(w-1)).astype(np.float32).ravel(),\n",
    "                  (yy/(h-1)).astype(np.float32).ravel()], axis=1)\n",
    "pred = model.predict(Xfull).reshape(h, w)\n",
    "acc  = binary_accuracy(pred.reshape(-1,1), mask.reshape(-1,1).astype(np.float32))\n",
    "print(\"map accuracy:\", acc)\n",
    "print(\"GT prior:\", mask.mean(), \"Pred prior:\", (pred>=0.5).mean())\n",
    "print(\"Loss plot:\", meta[\"plot_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d2048506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: runs_map\\relu_64x2_plain_bce\\pred_reconstructed_color.png and runs_map\\relu_64x2_plain_bce\\gt_color.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Colors (BGR as used by cv2)\n",
    "ORANGE_BGR = np.array([  0,165,255], dtype=np.uint8)  # class 1\n",
    "PURPLE_BGR = np.array([128,  0,128], dtype=np.uint8)  # class 0\n",
    "\n",
    "# 1) Threshold probabilities → binary classes\n",
    "pred_bin = (pred >= 0.5).astype(np.uint8)            # (h, w) in {0,1}\n",
    "\n",
    "# 2) Colorize prediction to match the original map’s palette\n",
    "pred_color = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "pred_color[pred_bin == 1] = ORANGE_BGR\n",
    "pred_color[pred_bin == 0] = PURPLE_BGR\n",
    "\n",
    "# 3) (Optional) Colorize the ground-truth mask too, for side-by-side\n",
    "gt_color = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "gt_color[mask == 1] = ORANGE_BGR\n",
    "gt_color[mask == 0] = PURPLE_BGR\n",
    "\n",
    "# 4) Save and show\n",
    "run_dir = meta[\"run_dir\"] if \"meta\" in globals() else \".\"\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "cv2.imwrite(os.path.join(run_dir, \"pred_reconstructed_color.png\"), pred_color)\n",
    "cv2.imwrite(os.path.join(run_dir, \"gt_color.png\"), gt_color)\n",
    "\n",
    "# display in notebook (matplotlib expects RGB)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.imshow(cv2.cvtColor(gt_color, cv2.COLOR_BGR2RGB));  plt.title(\"Ground Truth\"); plt.axis(\"off\")\n",
    "plt.subplot(1,2,2); plt.imshow(cv2.cvtColor(pred_color, cv2.COLOR_BGR2RGB)); plt.title(\"Reconstructed Prediction\"); plt.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"Saved:\",\n",
    "      os.path.join(run_dir, \"pred_reconstructed_color.png\"),\n",
    "      \"and\",\n",
    "      os.path.join(run_dir, \"gt_color.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c0371702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: runs_map\\relu_64x2_plain_bce\\map_triptych.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_dir = meta[\"run_dir\"]; ensure_dir(run_dir)\n",
    "\n",
    "pred_bin = (pred >= 0.5).astype(np.uint8)\n",
    "err = (pred_bin != mask).astype(np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(9,3))\n",
    "axs[0].imshow(mask, cmap=\"gray\", vmin=0, vmax=1); axs[0].set_title(\"Ground truth\"); axs[0].axis(\"off\")\n",
    "axs[1].imshow(pred_bin, cmap=\"gray\", vmin=0, vmax=1); axs[1].set_title(\"Prediction\"); axs[1].axis(\"off\")\n",
    "axs[2].imshow(mask, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axs[2].imshow(err, cmap=\"Reds\", alpha=0.6, vmin=0, vmax=1); axs[2].set_title(\"Errors\"); axs[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "outpath = os.path.join(run_dir, \"map_triptych.png\")\n",
    "plt.savefig(outpath, dpi=150); plt.close()\n",
    "print(\"saved:\", outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9e292f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   2%|▎         | 50/2000 [00:00<00:27, 71.27it/s]\n",
      "epochs:   2%|▎         | 50/2000 [00:02<01:29, 21.87it/s]\n",
      "epochs:   2%|▎         | 50/2000 [00:03<02:25, 13.43it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:05<03:11, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hidden': (64,), 'loss': 12.80421688079834, 'acc': 0.2056, 'epochs': 51, 'samples': 127500, 'dir': 'runs_map\\\\depth_64'}, {'hidden': (64, 64), 'loss': 3.2777543937683107, 'acc': 0.7944, 'epochs': 51, 'samples': 127500, 'dir': 'runs_map\\\\depth_64-64'}, {'hidden': (64, 64, 64), 'loss': 12.804217098999024, 'acc': 0.2056, 'epochs': 51, 'samples': 127500, 'dir': 'runs_map\\\\depth_64-64-64'}, {'hidden': (64, 64, 64, 64), 'loss': 3.277754390335083, 'acc': 0.7944, 'epochs': 52, 'samples': 130000, 'dir': 'runs_map\\\\depth_64-64-64-64'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   3%|▎         | 51/2000 [00:00<00:09, 204.52it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:00<00:07, 255.58it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:02<01:32, 21.06it/s]\n",
      "epochs:   2%|▎         | 50/2000 [00:02<01:51, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hidden': (16, 16), 'loss': 3.2777543952941897, 'acc': 0.7944, 'epochs': 52, 'samples': 130000, 'dir': 'runs_map\\\\width_16-16'}, {'hidden': (32, 32), 'loss': 3.277754396820068, 'acc': 0.7944, 'epochs': 52, 'samples': 130000, 'dir': 'runs_map\\\\width_32-32'}, {'hidden': (64, 64), 'loss': 3.2777543899536132, 'acc': 0.7944, 'epochs': 52, 'samples': 130000, 'dir': 'runs_map\\\\width_64-64'}, {'hidden': (128, 128), 'loss': 12.804216911315917, 'acc': 0.2056, 'epochs': 51, 'samples': 127500, 'dir': 'runs_map\\\\width_128-128'}]\n"
     ]
    }
   ],
   "source": [
    "def try_arch(hidden, lr=5e-3, tag=\"\"):\n",
    "    m = build_model(hidden=hidden, lr=lr, relu_bias=0.1)\n",
    "    meta, _ = train(m, X, Y, batch_size=256, grad_accum_steps=2,\n",
    "                    max_epochs=2000, patience=50, rel_improve_thresh=0.005,\n",
    "                    runs_dir=\"runs_map\", run_name=f\"{tag}_{'-'.join(map(str,hidden))}\",\n",
    "                    seed=None)\n",
    "    P = m.predict(Xfull).reshape(h,w)\n",
    "    acc = binary_accuracy(P.reshape(-1,1), mask.reshape(-1,1).astype(np.float32))\n",
    "    return dict(hidden=hidden, loss=meta[\"final_epoch_loss\"], acc=acc, epochs=meta[\"epochs_run\"], samples=meta[\"samples_seen\"], dir=meta[\"run_dir\"])\n",
    "\n",
    "# depth sweep @ fixed width=64\n",
    "depth_results = [try_arch(tuple([64]*d), tag=\"depth\") for d in (1,2,3,4)]\n",
    "print(depth_results)\n",
    "\n",
    "# width sweep @ fixed depth=2\n",
    "width_results = [try_arch((w_,w_), tag=\"width\") for w_ in (16,32,64,128)]\n",
    "print(width_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1ef93010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   2%|▎         | 50/2000 [00:03<02:00, 16.12it/s]\n",
      "epochs:   3%|▎         | 52/2000 [00:02<01:33, 20.87it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:01<00:54, 35.61it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:01<01:06, 29.33it/s]\n",
      "epochs:   3%|▎         | 51/2000 [00:01<01:05, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bs': 128, 'ga': 1, 'lr': 0.005, 'acc': 0.7944, 'loss': 3.2777543762207033, 'epochs': 51, 'samples': 127500, 'time': None, 'dir': 'runs_map\\\\hp_bs128_ga1_lr0.005'}\n",
      "{'bs': 256, 'ga': 2, 'lr': 0.005, 'acc': 0.7944, 'loss': 3.2777544036865236, 'epochs': 53, 'samples': 132500, 'time': None, 'dir': 'runs_map\\\\hp_bs256_ga2_lr0.005'}\n",
      "{'bs': 512, 'ga': 4, 'lr': 0.005, 'acc': 0.7944, 'loss': 3.277754373550415, 'epochs': 52, 'samples': 130000, 'time': None, 'dir': 'runs_map\\\\hp_bs512_ga4_lr0.005'}\n",
      "{'bs': 256, 'ga': 2, 'lr': 0.01, 'acc': 0.7944, 'loss': 3.2777543952941897, 'epochs': 52, 'samples': 130000, 'time': None, 'dir': 'runs_map\\\\hp_bs256_ga2_lr0.01'}\n",
      "{'bs': 256, 'ga': 2, 'lr': 0.002, 'acc': 0.7944, 'loss': 3.2777544162750245, 'epochs': 52, 'samples': 130000, 'time': None, 'dir': 'runs_map\\\\hp_bs256_ga2_lr0.002'}\n"
     ]
    }
   ],
   "source": [
    "def run_hparams(bs, ga, lr):\n",
    "    m = build_model(hidden=(64,64), lr=lr, relu_bias=0.1)\n",
    "    meta, _ = train(m, X, Y, batch_size=bs, grad_accum_steps=ga,\n",
    "                    max_epochs=2000, patience=50, rel_improve_thresh=0.005,\n",
    "                    runs_dir=\"runs_map\", run_name=f\"hp_bs{bs}_ga{ga}_lr{lr}\",\n",
    "                    seed=None)\n",
    "    P = m.predict(Xfull).reshape(h,w)\n",
    "    acc = binary_accuracy(P.reshape(-1,1), mask.reshape(-1,1).astype(np.float32))\n",
    "    return dict(bs=bs, ga=ga, lr=lr, acc=acc, loss=meta[\"final_epoch_loss\"],\n",
    "                epochs=meta[\"epochs_run\"], samples=meta[\"samples_seen\"], time=None, dir=meta[\"run_dir\"])\n",
    "\n",
    "hp_cfgs = [(128,1,5e-3),(256,2,5e-3),(512,4,5e-3),(256,2,1e-2),(256,2,2e-3)]\n",
    "hp_results = [run_hparams(*cfg) for cfg in hp_cfgs]\n",
    "for r in hp_results:\n",
    "    print(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
