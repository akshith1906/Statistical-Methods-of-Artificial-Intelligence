{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pretty_print_sklearn_tree import pretty_print_sklearn_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data from train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data: x_tr shape (6346, 7729), y_tr shape (6346,)\n"
     ]
    }
   ],
   "source": [
    "x_tr_NF = pd.read_csv('data/x_train.csv')\n",
    "y_tr_N = pd.read_csv('data/y_train.csv').values.squeeze()\n",
    "print(f\"Loaded training data: x_tr shape {x_tr_NF.shape}, y_tr shape {y_tr_N.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded validation data: x_va shape (792, 7729), y_va shape (792,)\n"
     ]
    }
   ],
   "source": [
    "x_va_NF = pd.read_csv('data/x_valid.csv').values\n",
    "y_va_N = pd.read_csv('data/y_valid.csv').values.squeeze()\n",
    "print(f\"Loaded validation data: x_va shape {x_va_NF.shape}, y_va shape {y_va_N.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data: x_te shape (793, 7729), y_te shape (793,)\n"
     ]
    }
   ],
   "source": [
    "x_te_NF = pd.read_csv('data/x_test.csv').values\n",
    "y_te_N = pd.read_csv('data/y_test.csv').values.squeeze()\n",
    "print(f\"Loaded test data: x_te shape {x_te_NF.shape}, y_te shape {y_te_N.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words: ['good', 'great', 'time', 'book', \"don't\"]\n"
     ]
    }
   ],
   "source": [
    "vocab_list = x_tr_NF.columns\n",
    "print(f\"First 10 words: {vocab_list[:5].to_list()}\")\n",
    "\n",
    "x_tr_NF = x_tr_NF.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack training and validation sets into big arrays (so we can use sklearn's hyperparameter search tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0]))\n",
      "(7138,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "x_tr_va_NF = np.vstack([x_tr_NF, x_va_NF])\n",
    "y_tr_va_N = np.hstack([y_tr_N, y_va_N])\n",
    "\n",
    "# Get the size of the original training set\n",
    "N_tr = x_tr_NF.shape[0]\n",
    "N_va = x_va_NF.shape[0]\n",
    "\n",
    "# -1 for training samples, 0 for validation\n",
    "test_fold = np.concatenate([\n",
    "    -1 * np.ones(N_tr, dtype=int),\n",
    "     0 * np.ones(N_va, dtype=int)\n",
    "])\n",
    "\n",
    "my_split = PredefinedSplit(test_fold)\n",
    "\n",
    "print(my_split)\n",
    "print(test_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Decision Trees\n",
    "\n",
    "## 1A: Train a simple tree with depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_tree classifier object created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "simple_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "print(\"small_tree classifier object created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit the tree** \n",
    "\n",
    "**TODO Train on the training set** in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=101)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_tree.fit(x_tr_NF, y_tr_N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Figure 1: Print Tree** \n",
    "\n",
    "Use a helper function from the starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 15 nodes.\n",
      "- depth   0 has    1 nodes, of which    0 are leaves\n",
      "- depth   1 has    2 nodes, of which    0 are leaves\n",
      "- depth   2 has    4 nodes, of which    0 are leaves\n",
      "- depth   3 has    8 nodes, of which    8 are leaves\n",
      "The decision tree:  (Note: Y = 'yes' to above question; N = 'no')\n",
      "Decision: X['great'] <= 0.50?\n",
      "  Y Decision: X['excel'] <= 0.50?\n",
      "    Y Decision: X['disappoint'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.430 (4041 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.114 (368 total training examples)\n",
      "    N Decision: X['disappoint'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.903 (277 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.429 (14 total training examples)\n",
      "  N Decision: X['return'] <= 0.50?\n",
      "    Y Decision: X['bad'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.745 (1413 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.415 (142 total training examples)\n",
      "    N Decision: X['movie'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.190 (79 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.833 (12 total training examples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_sklearn_tree(simple_tree, vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Question: The tree is asking a math question: Is X['great'] <= 0.50?\n",
    "\n",
    "The Feature: Your features are binary:\n",
    "\n",
    "0 if the word is absent.\n",
    "\n",
    "1 if the word is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes there is an internal class like that\n",
    "\n",
    "      Y Leaf: p(y=1 | this leaf) = 0.430 (4041 total training examples)\n",
    "      N Leaf: p(y=1 | this leaf) = 0.114 (368 total training examples)\n",
    "\n",
    "Yes, it is very common and makes perfect sense for a node to split into two children that predict the same class.\n",
    "\n",
    "The reason is that the decision tree's goal at each step is not to change the final prediction, but to create two new groups that are as pure as possible.\n",
    "\n",
    "The algorithm uses a metric like Gini Impurity to decide the best split. A \"pure\" node is one where all the samples belong to a single class (e.g., 100% positive). The tree will make any split that reduces the overall impurity, even if the majority class in both new groups remains the same.\n",
    "\n",
    "\n",
    "Even though both groups  predict Negative, the algorithm considers this a success. It has successfully isolated a very confidently negative group from a less certain one.\n",
    "The best choice at each step is to create two cleaner, but still negative-predicting, groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B : Find best Decision Tree with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV object for Decision Tree created.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the base estimator\n",
    "base_tree = sklearn.tree.DecisionTreeClassifier(criterion='gini', random_state=101)\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [2, 8, 32, 128],\n",
    "    'min_samples_leaf': [1, 3, 9],\n",
    "    'random_state': [101]\n",
    "}\n",
    "\n",
    "searcher_dt = GridSearchCV(\n",
    "    estimator=base_tree,\n",
    "    param_grid=param_grid_dt,\n",
    "    scoring='balanced_accuracy',  \n",
    "    cv=my_split,             \n",
    "    return_train_score=True,\n",
    "    refit=False,                \n",
    ")\n",
    "\n",
    "print(\"GridSearchCV object for Decision Tree created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'max_depth': 32, 'min_samples_leaf': 3, 'random_state': 101}\n",
      "\n",
      "Top 5 results:\n",
      "   param_max_depth param_min_samples_leaf param_random_state  mean_test_score\n",
      "7               32                      3                101         0.732380\n",
      "9              128                      1                101         0.730313\n",
      "6               32                      1                101         0.727378\n",
      "11             128                      9                101         0.723193\n",
      "10             128                      3                101         0.716495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "searcher_dt.fit(x_tr_va_NF, y_tr_va_N)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(searcher_dt.best_params_)\n",
    "\n",
    "print(\"\\nTop 5 results:\")\n",
    "results_dt_df = pd.DataFrame(searcher_dt.cv_results_)\n",
    "rel_cols = [c for c in results_dt_df.columns if 'param_' in c or 'mean_test_score' in c]\n",
    "print(results_dt_df[rel_cols].sort_values('mean_test_score', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Build the Best Tree on the training set** in the next coding cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=32, min_samples_leaf=3, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=32, min_samples_leaf=3, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=32, min_samples_leaf=3, random_state=101)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = base_tree .set_params(**searcher_dt.best_params_)\n",
    "best_tree.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the best decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 817 nodes.\n",
      "- depth   0 has    1 nodes, of which    0 are leaves\n",
      "- depth   1 has    2 nodes, of which    0 are leaves\n",
      "- depth   2 has    4 nodes, of which    0 are leaves\n",
      "- depth   3 has    8 nodes, of which    0 are leaves\n",
      "- depth   4 has   16 nodes, of which    6 are leaves\n",
      "- depth   5 has   20 nodes, of which    5 are leaves\n",
      "- depth   6 has   30 nodes, of which   14 are leaves\n",
      "- depth   7 has   32 nodes, of which   18 are leaves\n",
      "- depth   8 has   28 nodes, of which   12 are leaves\n",
      "- depth   9 has   32 nodes, of which   11 are leaves\n",
      "- depth  10 has   42 nodes, of which   21 are leaves\n",
      "- depth  11 has   42 nodes, of which   23 are leaves\n",
      "- depth  12 has   38 nodes, of which   17 are leaves\n",
      "- depth  13 has   42 nodes, of which   21 are leaves\n",
      "- depth  14 has   42 nodes, of which   25 are leaves\n",
      "- depth  15 has   34 nodes, of which   18 are leaves\n",
      "- depth  16 has   32 nodes, of which   14 are leaves\n",
      "- depth  17 has   36 nodes, of which   23 are leaves\n",
      "- depth  18 has   26 nodes, of which   14 are leaves\n",
      "- depth  19 has   24 nodes, of which    9 are leaves\n",
      "- depth  20 has   30 nodes, of which   14 are leaves\n",
      "- depth  21 has   32 nodes, of which   16 are leaves\n",
      "- depth  22 has   32 nodes, of which   19 are leaves\n",
      "- depth  23 has   26 nodes, of which   15 are leaves\n",
      "- depth  24 has   22 nodes, of which   11 are leaves\n",
      "- depth  25 has   22 nodes, of which   11 are leaves\n",
      "- depth  26 has   22 nodes, of which   11 are leaves\n",
      "- depth  27 has   22 nodes, of which   14 are leaves\n",
      "- depth  28 has   16 nodes, of which    9 are leaves\n",
      "- depth  29 has   14 nodes, of which    6 are leaves\n",
      "- depth  30 has   16 nodes, of which    8 are leaves\n",
      "- depth  31 has   16 nodes, of which    8 are leaves\n",
      "- depth  32 has   16 nodes, of which   16 are leaves\n",
      "The decision tree:  (Note: Y = 'yes' to above question; N = 'no')\n",
      "Decision: X['great'] <= 0.50?\n",
      "  Y Decision: X['excel'] <= 0.50?\n",
      "    Y Decision: X['disappoint'] <= 0.50?\n",
      "      Y Decision: X['easy'] <= 0.50?\n",
      "        Y Decision: X['love'] <= 0.50?\n",
      "          Y Decision: X['waste'] <= 0.50?\n",
      "            Y Decision: X['bad'] <= 0.50?\n",
      "              Y Decision: X['poor'] <= 0.50?\n",
      "                Y Decision: X['the_best'] <= 0.50?\n",
      "                  Y Decision: X['return'] <= 0.50?\n",
      "                    Y Decision: X['perfect'] <= 0.50?\n",
      "                      Y Decision: X['worst'] <= 0.50?\n",
      "                        Y Decision: X['bore'] <= 0.50?\n",
      "                          Y Decision: X['enjoy'] <= 0.50?\n",
      "                            Y Decision: X['a_must'] <= 0.50?\n",
      "                              Y Decision: X['highly_recommend'] <= 0.50?\n",
      "                                Y Decision: X['amaz'] <= 0.50?\n",
      "                                  Y Decision: X['good'] <= 0.50?\n",
      "                                    Y Decision: X['loved'] <= 0.50?\n",
      "                                      Y Decision: X['beauti'] <= 0.50?\n",
      "                                        Y Decision: X['univers'] <= 0.50?\n",
      "                                          Y Decision: X['knowledg'] <= 0.50?\n",
      "                                            Y Decision: X['well_worth'] <= 0.50?\n",
      "                                              Y Decision: X['favorit'] <= 0.50?\n",
      "                                                Y Decision: X['back'] <= 0.50?\n",
      "                                                  Y Decision: X['smooth'] <= 0.50?\n",
      "                                                    Y Decision: X['wonder'] <= 0.50?\n",
      "                                                      Y Decision: X['am_very'] <= 0.50?\n",
      "                                                        Y Decision: X['outstand'] <= 0.50?\n",
      "                                                          Y Decision: X['complex'] <= 0.50?\n",
      "                                                            Y Decision: X['fantast'] <= 0.50?\n",
      "                                                              Y Decision: X['work'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.332 (945 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.193 (187 total training examples)\n",
      "                                                              N Decision: X['didn't'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                            N Decision: X['book'] <= 0.50?\n",
      "                                                              Y Leaf: p(y=1 | this leaf) = 1.000 (8 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "                                                      N Decision: X['but_i'] <= 0.50?\n",
      "                                                        Y Decision: X['final'] <= 0.50?\n",
      "                                                          Y Decision: X['it_was'] <= 0.50?\n",
      "                                                            Y Decision: X['doesn't'] <= 0.50?\n",
      "                                                              Y Leaf: p(y=1 | this leaf) = 1.000 (19 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                                                    N Decision: X['this_mouse'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 1.000 (11 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                  N Decision: X['this_movie'] <= 1.50?\n",
      "                                                    Y Decision: X['us_that'] <= 0.50?\n",
      "                                                      Y Decision: X['includ'] <= 0.50?\n",
      "                                                        Y Decision: X['back_up'] <= 0.50?\n",
      "                                                          Y Decision: X['when_she'] <= 0.50?\n",
      "                                                            Y Decision: X['to_my'] <= 0.50?\n",
      "                                                              Y Decision: X['with_my'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.030 (101 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.286 (7 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                                N Decision: X['you_are'] <= 0.50?\n",
      "                                                  Y Decision: X['it_was'] <= 0.50?\n",
      "                                                    Y Decision: X['i_also'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 1.000 (14 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "                                            N Decision: X['comput'] <= 0.50?\n",
      "                                              Y Decision: X['charact'] <= 0.50?\n",
      "                                                Y Leaf: p(y=1 | this leaf) = 1.000 (12 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                          N Decision: X['learn'] <= 0.50?\n",
      "                                            Y Leaf: p(y=1 | this leaf) = 1.000 (11 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                        N Decision: X['buy'] <= 0.50?\n",
      "                                          Y Decision: X['dvd'] <= 0.50?\n",
      "                                            Y Decision: X['exist'] <= 0.50?\n",
      "                                              Y Decision: X['feel'] <= 0.50?\n",
      "                                                Y Leaf: p(y=1 | this leaf) = 1.000 (25 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                          N Decision: X['beauti'] <= 1.50?\n",
      "                                            Y Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                                      N Decision: X['point'] <= 0.50?\n",
      "                                        Y Decision: X['stop'] <= 0.50?\n",
      "                                          Y Decision: X['friend'] <= 0.50?\n",
      "                                            Y Leaf: p(y=1 | this leaf) = 1.000 (24 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                    N Decision: X['bit'] <= 0.50?\n",
      "                                      Y Decision: X['thing'] <= 0.50?\n",
      "                                        Y Decision: X['very_good'] <= 0.50?\n",
      "                                          Y Decision: X['going_to'] <= 0.50?\n",
      "                                            Y Decision: X['peopl'] <= 0.50?\n",
      "                                              Y Decision: X['call'] <= 0.50?\n",
      "                                                Y Decision: X['nice'] <= 0.50?\n",
      "                                                  Y Decision: X['good_but'] <= 0.50?\n",
      "                                                    Y Decision: X['good'] <= 1.50?\n",
      "                                                      Y Decision: X['hard'] <= 0.50?\n",
      "                                                        Y Decision: X['i_just'] <= 0.50?\n",
      "                                                          Y Decision: X['correct'] <= 0.50?\n",
      "                                                            Y Decision: X['use_it'] <= 0.50?\n",
      "                                                              Y Decision: X['cut'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.597 (144 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.143 (7 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                                                          N Decision: X['i_had'] <= 0.50?\n",
      "                                                            Y Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                                                      N Decision: X['is_no'] <= 0.50?\n",
      "                                                        Y Decision: X['speaker'] <= 1.00?\n",
      "                                                          Y Decision: X['not_a'] <= 0.50?\n",
      "                                                            Y Decision: X['time'] <= 0.50?\n",
      "                                                              Y Decision: X['qualiti'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.767 (30 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 1.000 (8 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                                                    N Decision: X['the_sound'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                  N Decision: X['when_i'] <= 0.50?\n",
      "                                                    Y Decision: X['point'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 1.000 (14 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                N Decision: X['i'm'] <= 0.50?\n",
      "                                                  Y Leaf: p(y=1 | this leaf) = 0.000 (10 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                              N Decision: X['a_few'] <= 0.50?\n",
      "                                                Y Decision: X['as_well'] <= 0.50?\n",
      "                                                  Y Leaf: p(y=1 | this leaf) = 0.000 (17 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.000 (13 total training examples)\n",
      "                                          N Decision: X['miseri'] <= 0.50?\n",
      "                                            Y Decision: X['read'] <= 0.50?\n",
      "                                              Y Decision: X['for_<num>'] <= 0.50?\n",
      "                                                Y Decision: X['thought'] <= 0.50?\n",
      "                                                  Y Leaf: p(y=1 | this leaf) = 1.000 (32 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                        N Decision: X['perspect'] <= 0.50?\n",
      "                                          Y Decision: X['the_plot'] <= 0.50?\n",
      "                                            Y Decision: X['stars'] <= 0.50?\n",
      "                                              Y Decision: X['i_bought'] <= 0.50?\n",
      "                                                Y Decision: X['handl'] <= 0.50?\n",
      "                                                  Y Decision: X['short'] <= 0.50?\n",
      "                                                    Y Decision: X['job'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 0.000 (41 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                N Decision: X['a_good'] <= 0.50?\n",
      "                                                  Y Decision: X['bought_this'] <= 0.50?\n",
      "                                                    Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                      N Decision: X['thought'] <= 0.50?\n",
      "                                        Y Decision: X['imagin'] <= 0.50?\n",
      "                                          Y Leaf: p(y=1 | this leaf) = 1.000 (27 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Decision: X['money'] <= 0.50?\n",
      "                                    Y Decision: X['long'] <= 0.50?\n",
      "                                      Y Decision: X['ridicul'] <= 0.50?\n",
      "                                        Y Decision: X['title'] <= 0.50?\n",
      "                                          Y Decision: X['the_same'] <= 0.50?\n",
      "                                            Y Decision: X['i_used'] <= 0.50?\n",
      "                                              Y Leaf: p(y=1 | this leaf) = 1.000 (38 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                N Decision: X['to_my'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 1.000 (26 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                              N Decision: X['should_be'] <= 0.50?\n",
      "                                Y Leaf: p(y=1 | this leaf) = 1.000 (29 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                            N Decision: X['i_could'] <= 0.50?\n",
      "                              Y Decision: X['left'] <= 0.50?\n",
      "                                Y Decision: X['write'] <= 1.50?\n",
      "                                  Y Decision: X['they_were'] <= 0.50?\n",
      "                                    Y Decision: X['interest'] <= 1.50?\n",
      "                                      Y Decision: X['puts'] <= 0.50?\n",
      "                                        Y Decision: X['i_enjoy'] <= 0.50?\n",
      "                                          Y Decision: X['and_so'] <= 0.50?\n",
      "                                            Y Decision: X['you_might'] <= 0.50?\n",
      "                                              Y Decision: X['i'm'] <= 0.50?\n",
      "                                                Y Leaf: p(y=1 | this leaf) = 1.000 (69 total training examples)\n",
      "                                                N Decision: X['read'] <= 0.50?\n",
      "                                                  Y Decision: X['i'm_not'] <= 0.50?\n",
      "                                                    Y Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                          N Decision: X['is_also'] <= 0.50?\n",
      "                            Y Decision: X['practic'] <= 0.50?\n",
      "                              Y Decision: X['i_like'] <= 0.50?\n",
      "                                Y Leaf: p(y=1 | this leaf) = 0.000 (59 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                        N Decision: X['state'] <= 0.50?\n",
      "                          Y Decision: X['featur'] <= 0.50?\n",
      "                            Y Decision: X['it_out'] <= 0.50?\n",
      "                              Y Leaf: p(y=1 | this leaf) = 0.000 (69 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                      N Decision: X['turn'] <= 1.50?\n",
      "                        Y Decision: X['shouldn't'] <= 0.50?\n",
      "                          Y Decision: X['is_better'] <= 0.50?\n",
      "                            Y Decision: X['worse'] <= 0.50?\n",
      "                              Y Decision: X['a_good'] <= 0.50?\n",
      "                                Y Decision: X['coffe'] <= 2.00?\n",
      "                                  Y Decision: X['purpos'] <= 0.50?\n",
      "                                    Y Decision: X['star'] <= 0.50?\n",
      "                                      Y Decision: X['city'] <= 0.50?\n",
      "                                        Y Leaf: p(y=1 | this leaf) = 1.000 (76 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                N Decision: X['this_book'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                    N Decision: X['write'] <= 0.50?\n",
      "                      Y Decision: X['team'] <= 0.50?\n",
      "                        Y Decision: X['funny'] <= 0.50?\n",
      "                          Y Decision: X['hard'] <= 0.50?\n",
      "                            Y Decision: X['don't'] <= 1.50?\n",
      "                              Y Decision: X['very_good'] <= 0.50?\n",
      "                                Y Decision: X['the_usual'] <= 0.50?\n",
      "                                  Y Decision: X['medium'] <= 0.50?\n",
      "                                    Y Leaf: p(y=1 | this leaf) = 0.000 (127 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                            N Decision: X['i_was'] <= 0.50?\n",
      "                              Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                      N Decision: X['time'] <= 0.50?\n",
      "                        Y Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "                  N Decision: X['and_i'm'] <= 0.50?\n",
      "                    Y Decision: X['not_a'] <= 0.50?\n",
      "                      Y Decision: X['call'] <= 0.50?\n",
      "                        Y Decision: X['bore'] <= 0.50?\n",
      "                          Y Decision: X['vast'] <= 0.50?\n",
      "                            Y Decision: X['can_say'] <= 0.50?\n",
      "                              Y Decision: X['did_not'] <= 0.50?\n",
      "                                Y Decision: X['so_i'] <= 0.50?\n",
      "                                  Y Decision: X['before_you'] <= 0.50?\n",
      "                                    Y Decision: X['feels'] <= 0.50?\n",
      "                                      Y Decision: X['way_to'] <= 0.50?\n",
      "                                        Y Decision: X['ever_owned'] <= 0.50?\n",
      "                                          Y Decision: X['best_in'] <= 0.50?\n",
      "                                            Y Leaf: p(y=1 | this leaf) = 1.000 (98 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                  N Decision: X['book'] <= 0.50?\n",
      "                                    Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                N Decision: X['film'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                        N Decision: X['if_you'] <= 0.50?\n",
      "                          Y Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                      N Decision: X['action'] <= 0.50?\n",
      "                        Y Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                N Decision: X['pretti'] <= 0.50?\n",
      "                  Y Decision: X['histori'] <= 0.50?\n",
      "                    Y Decision: X['build'] <= 0.50?\n",
      "                      Y Decision: X['a_better'] <= 0.50?\n",
      "                        Y Decision: X['the_book'] <= 0.50?\n",
      "                          Y Decision: X['poor'] <= 2.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.000 (115 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Decision: X['book'] <= 1.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                        N Decision: X['i_am'] <= 0.50?\n",
      "                          Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                    N Decision: X['good'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                  N Decision: X['book'] <= 1.00?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "              N Decision: X['perfect'] <= 0.50?\n",
      "                Y Decision: X['about_this'] <= 0.50?\n",
      "                  Y Decision: X['beat'] <= 0.50?\n",
      "                    Y Decision: X['escap'] <= 0.50?\n",
      "                      Y Decision: X['i_recommend'] <= 0.50?\n",
      "                        Y Decision: X['entertain'] <= 0.50?\n",
      "                          Y Decision: X['it_works'] <= 0.50?\n",
      "                            Y Decision: X['what_you'] <= 0.50?\n",
      "                              Y Decision: X['a_strong'] <= 0.50?\n",
      "                                Y Decision: X['the_front'] <= 0.50?\n",
      "                                  Y Decision: X['travel'] <= 0.50?\n",
      "                                    Y Decision: X['this_i'] <= 0.50?\n",
      "                                      Y Decision: X['most_part'] <= 0.50?\n",
      "                                        Y Decision: X['a_small'] <= 0.50?\n",
      "                                          Y Decision: X['while_the'] <= 0.50?\n",
      "                                            Y Leaf: p(y=1 | this leaf) = 0.000 (226 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                              N Decision: X['the_first'] <= 0.50?\n",
      "                                Y Decision: X['worth'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                  N Decision: X['find'] <= 0.50?\n",
      "                    Y Decision: X['read'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                N Decision: X['problem'] <= 0.50?\n",
      "                  Y Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 1.000 (6 total training examples)\n",
      "            N Decision: X['market'] <= 0.50?\n",
      "              Y Decision: X['book_and'] <= 0.50?\n",
      "                Y Decision: X['is_probably'] <= 0.50?\n",
      "                  Y Decision: X['shame'] <= 0.50?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 0.000 (149 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "          N Decision: X['waste'] <= 0.50?\n",
      "            Y Decision: X['worst'] <= 0.50?\n",
      "              Y Decision: X['didn't'] <= 0.50?\n",
      "                Y Decision: X['bad'] <= 1.50?\n",
      "                  Y Decision: X['because_they'] <= 0.50?\n",
      "                    Y Decision: X['proper'] <= 0.50?\n",
      "                      Y Decision: X['i_finally'] <= 0.50?\n",
      "                        Y Decision: X['badly'] <= 0.50?\n",
      "                          Y Decision: X['chapter'] <= 0.50?\n",
      "                            Y Decision: X['issue'] <= 1.50?\n",
      "                              Y Decision: X['was_not'] <= 0.50?\n",
      "                                Y Decision: X['why_do'] <= 0.50?\n",
      "                                  Y Decision: X['tried_to'] <= 0.50?\n",
      "                                    Y Decision: X['not_worth'] <= 0.50?\n",
      "                                      Y Decision: X['poor'] <= 0.50?\n",
      "                                        Y Decision: X['watch'] <= 3.50?\n",
      "                                          Y Decision: X['work_for'] <= 0.50?\n",
      "                                            Y Decision: X['many_times'] <= 0.50?\n",
      "                                              Y Decision: X['evid'] <= 0.50?\n",
      "                                                Y Decision: X['happen'] <= 0.50?\n",
      "                                                  Y Decision: X['behavior'] <= 0.50?\n",
      "                                                    Y Decision: X['poetri'] <= 0.50?\n",
      "                                                      Y Decision: X['dry'] <= 0.50?\n",
      "                                                        Y Decision: X['save_your'] <= 0.50?\n",
      "                                                          Y Decision: X['car'] <= 0.50?\n",
      "                                                            Y Decision: X['jackson'] <= 0.50?\n",
      "                                                              Y Decision: X['cloth'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.969 (225 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                                              N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                  N Decision: X['make'] <= 0.50?\n",
      "                                                    Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                    N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.200 (5 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                N Decision: X['make'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                            N Decision: X['book'] <= 1.50?\n",
      "                              Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                    N Decision: X['them_because'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                  N Decision: X['short'] <= 0.50?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                N Decision: X['if_you'] <= 0.50?\n",
      "                  Y Decision: X['charact'] <= 0.50?\n",
      "                    Y Decision: X['thing'] <= 0.50?\n",
      "                      Y Decision: X['bought'] <= 0.50?\n",
      "                        Y Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                    N Decision: X['mysteri'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 0.000 (9 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                  N Decision: X['you_don't'] <= 0.50?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "              N Decision: X['recent'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.000 (9 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (17 total training examples)\n",
      "        N Decision: X['bad'] <= 0.50?\n",
      "          Y Decision: X['major'] <= 0.50?\n",
      "            Y Decision: X['not_recommend'] <= 0.50?\n",
      "              Y Decision: X['or_two'] <= 0.50?\n",
      "                Y Decision: X['book_is'] <= 1.50?\n",
      "                  Y Decision: X['get_what'] <= 0.50?\n",
      "                    Y Decision: X['daughter'] <= 0.50?\n",
      "                      Y Decision: X['this_product'] <= 1.50?\n",
      "                        Y Decision: X['extrem'] <= 0.50?\n",
      "                          Y Decision: X['slow'] <= 0.50?\n",
      "                            Y Decision: X['to_make'] <= 0.50?\n",
      "                              Y Decision: X['useless'] <= 0.50?\n",
      "                                Y Decision: X['bought_it'] <= 0.50?\n",
      "                                  Y Decision: X['film'] <= 0.50?\n",
      "                                    Y Decision: X['good_for'] <= 0.50?\n",
      "                                      Y Decision: X['thin'] <= 0.50?\n",
      "                                        Y Decision: X['inch'] <= 0.50?\n",
      "                                          Y Decision: X['card'] <= 0.50?\n",
      "                                            Y Decision: X['hook'] <= 0.50?\n",
      "                                              Y Leaf: p(y=1 | this leaf) = 1.000 (163 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                        N Decision: X['price'] <= 0.50?\n",
      "                                          Y Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "                                      N Decision: X['a_very'] <= 0.50?\n",
      "                                        Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                              N Decision: X['power'] <= 0.50?\n",
      "                                Y Decision: X['concept'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "          N Decision: X['qualiti'] <= 0.50?\n",
      "            Y Decision: X['it_doesn't'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (10 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "      N Decision: X['be_disappointed'] <= 0.50?\n",
      "        Y Decision: X['televis'] <= 0.50?\n",
      "          Y Decision: X['and_never'] <= 0.50?\n",
      "            Y Decision: X['story_and'] <= 0.50?\n",
      "              Y Decision: X['room'] <= 0.50?\n",
      "                Y Decision: X['led_to'] <= 0.50?\n",
      "                  Y Decision: X['the_english'] <= 0.50?\n",
      "                    Y Decision: X['have_never'] <= 0.50?\n",
      "                      Y Decision: X['a_little'] <= 0.50?\n",
      "                        Y Decision: X['of_his'] <= 0.50?\n",
      "                          Y Decision: X['second_time'] <= 0.50?\n",
      "                            Y Decision: X['entertain'] <= 1.50?\n",
      "                              Y Leaf: p(y=1 | this leaf) = 0.000 (294 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Decision: X['bad'] <= 0.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                        N Decision: X['was_not'] <= 0.50?\n",
      "                          Y Decision: X['book'] <= 0.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.000 (7 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "        N Decision: X['the_way'] <= 0.50?\n",
      "          Y Decision: X['that_i'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 1.000 (11 total training examples)\n",
      "            N Decision: X['a_few'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "    N Decision: X['disappoint'] <= 0.50?\n",
      "      Y Decision: X['imagin'] <= 0.50?\n",
      "        Y Decision: X['stuck'] <= 0.50?\n",
      "          Y Decision: X['publish'] <= 0.50?\n",
      "            Y Decision: X['think_the'] <= 0.50?\n",
      "              Y Decision: X['mr'] <= 0.50?\n",
      "                Y Decision: X['asian'] <= 0.50?\n",
      "                  Y Decision: X['defect'] <= 0.50?\n",
      "                    Y Decision: X['<dash-num>'] <= 0.50?\n",
      "                      Y Decision: X['of_our'] <= 0.50?\n",
      "                        Y Decision: X['leave'] <= 0.50?\n",
      "                          Y Decision: X['unit'] <= 2.00?\n",
      "                            Y Decision: X['hp'] <= 0.50?\n",
      "                              Y Decision: X['user'] <= 0.50?\n",
      "                                Y Leaf: p(y=1 | this leaf) = 1.000 (229 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 0.200 (5 total training examples)\n",
      "      N Decision: X['qualiti'] <= 0.50?\n",
      "        Y Decision: X['story'] <= 0.50?\n",
      "          Y Decision: X['work'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "  N Decision: X['return'] <= 0.50?\n",
      "    Y Decision: X['bad'] <= 0.50?\n",
      "      Y Decision: X['disappoint'] <= 0.50?\n",
      "        Y Decision: X['worst'] <= 0.50?\n",
      "          Y Decision: X['great_but'] <= 0.50?\n",
      "            Y Decision: X['don't_buy'] <= 0.50?\n",
      "              Y Decision: X['bore'] <= 0.50?\n",
      "                Y Decision: X['the_problem'] <= 0.50?\n",
      "                  Y Decision: X['tried_to'] <= 0.50?\n",
      "                    Y Decision: X['poor'] <= 0.50?\n",
      "                      Y Decision: X['not_great'] <= 0.50?\n",
      "                        Y Decision: X['worse'] <= 0.50?\n",
      "                          Y Decision: X['started_to'] <= 0.50?\n",
      "                            Y Decision: X['your_money'] <= 0.50?\n",
      "                              Y Decision: X['signific'] <= 0.50?\n",
      "                                Y Decision: X['awful'] <= 0.50?\n",
      "                                  Y Decision: X['worked_great'] <= 0.50?\n",
      "                                    Y Decision: X['that_great'] <= 0.50?\n",
      "                                      Y Decision: X['fair'] <= 0.50?\n",
      "                                        Y Decision: X['too_small'] <= 0.50?\n",
      "                                          Y Decision: X['potenti'] <= 0.50?\n",
      "                                            Y Decision: X['stopped_working'] <= 0.50?\n",
      "                                              Y Decision: X['market'] <= 1.50?\n",
      "                                                Y Decision: X['lies'] <= 0.50?\n",
      "                                                  Y Decision: X['of_work'] <= 0.50?\n",
      "                                                    Y Decision: X['shame'] <= 0.50?\n",
      "                                                      Y Decision: X['went_out'] <= 0.50?\n",
      "                                                        Y Decision: X['agree_that'] <= 0.50?\n",
      "                                                          Y Decision: X['it_didn't'] <= 0.50?\n",
      "                                                            Y Decision: X['would_not'] <= 0.50?\n",
      "                                                              Y Decision: X['work_with'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.917 (985 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 0.429 (7 total training examples)\n",
      "                                                              N Decision: X['purchas'] <= 0.50?\n",
      "                                                                Y Leaf: p(y=1 | this leaf) = 0.167 (6 total training examples)\n",
      "                                                                N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "                                                            N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                                          N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                                                      N Decision: X['care'] <= 0.50?\n",
      "                                                        Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                                    N Decision: X['a_lot'] <= 0.50?\n",
      "                                                      Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.200 (5 total training examples)\n",
      "                                            N Decision: X['charact'] <= 1.50?\n",
      "                                              Y Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                        N Decision: X['the_first'] <= 0.50?\n",
      "                                          Y Decision: X['uneven'] <= 0.50?\n",
      "                                            Y Decision: X['if_you'] <= 0.50?\n",
      "                                              Y Decision: X['they_are'] <= 0.50?\n",
      "                                                Y Leaf: p(y=1 | this leaf) = 1.000 (12 total training examples)\n",
      "                                                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                            N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                                      N Decision: X['and_i'] <= 0.50?\n",
      "                                        Y Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                                        N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                    N Decision: X['charg'] <= 0.50?\n",
      "                                      Y Decision: X['it_worked'] <= 0.50?\n",
      "                                        Y Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "                                        N Decision: X['so_i'] <= 0.50?\n",
      "                                          Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "                                  N Decision: X['peopl'] <= 0.50?\n",
      "                                    Y Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                                N Decision: X['book'] <= 1.00?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                              N Decision: X['review'] <= 0.50?\n",
      "                                Y Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "                                N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "                          N Decision: X['high'] <= 0.50?\n",
      "                            Y Decision: X['don't'] <= 0.50?\n",
      "                              Y Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.000 (7 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                        N Decision: X['don't'] <= 0.50?\n",
      "                          Y Leaf: p(y=1 | this leaf) = 0.000 (7 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                      N Decision: X['i've'] <= 0.50?\n",
      "                        Y Decision: X['don't'] <= 0.50?\n",
      "                          Y Decision: X['difficult_to'] <= 0.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.000 (13 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Decision: X['special'] <= 0.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 1.000 (6 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "                    N Decision: X['to_make'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                  N Decision: X['a_good'] <= 0.50?\n",
      "                    Y Decision: X['because_i'] <= 0.50?\n",
      "                      Y Decision: X['review'] <= 0.50?\n",
      "                        Y Leaf: p(y=1 | this leaf) = 0.000 (12 total training examples)\n",
      "                        N Decision: X['bought_this'] <= 0.50?\n",
      "                          Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                    N Decision: X['and_i'] <= 0.50?\n",
      "                      Y Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                N Decision: X['day'] <= 0.50?\n",
      "                  Y Decision: X['begin'] <= 0.50?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 0.000 (12 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "            N Decision: X['years'] <= 0.50?\n",
      "              Y Decision: X['cook'] <= 0.50?\n",
      "                Y Decision: X['purchas'] <= 0.50?\n",
      "                  Y Decision: X['sound'] <= 0.50?\n",
      "                    Y Decision: X['it_was'] <= 0.50?\n",
      "                      Y Decision: X['problem'] <= 0.50?\n",
      "                        Y Decision: X['kitchenaid'] <= 0.50?\n",
      "                          Y Leaf: p(y=1 | this leaf) = 1.000 (16 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "                  N Decision: X['i_am'] <= 0.50?\n",
      "                    Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (5 total training examples)\n",
      "              N Decision: X['money'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "          N Decision: X['real'] <= 0.50?\n",
      "            Y Decision: X['of_all'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (19 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "        N Decision: X['be_disappointed'] <= 0.50?\n",
      "          Y Decision: X['was_not'] <= 0.50?\n",
      "            Y Decision: X['excel'] <= 0.50?\n",
      "              Y Decision: X['of_my'] <= 0.50?\n",
      "                Y Decision: X['you'll'] <= 0.50?\n",
      "                  Y Decision: X['to_see'] <= 0.50?\n",
      "                    Y Decision: X['the_beginning'] <= 0.50?\n",
      "                      Y Decision: X['to_read'] <= 0.50?\n",
      "                        Y Decision: X['story'] <= 0.50?\n",
      "                          Y Decision: X['pick'] <= 0.50?\n",
      "                            Y Leaf: p(y=1 | this leaf) = 0.000 (37 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "            N Decision: X['kind_of'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "          N Decision: X['back'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "      N Decision: X['is_really'] <= 0.50?\n",
      "        Y Decision: X['run'] <= 0.50?\n",
      "          Y Decision: X['enjoy'] <= 1.50?\n",
      "            Y Decision: X['love_it'] <= 0.50?\n",
      "              Y Decision: X['perfect'] <= 1.50?\n",
      "                Y Decision: X['spoken'] <= 0.50?\n",
      "                  Y Decision: X['not_bad'] <= 0.50?\n",
      "                    Y Decision: X['surpris'] <= 1.50?\n",
      "                      Y Decision: X['cook'] <= 0.50?\n",
      "                        Y Decision: X['excel'] <= 0.50?\n",
      "                          Y Decision: X['wanted_to'] <= 0.50?\n",
      "                            Y Decision: X['machin'] <= 0.50?\n",
      "                              Y Decision: X['i_use'] <= 0.50?\n",
      "                                Y Decision: X['usual'] <= 0.50?\n",
      "                                  Y Decision: X['element'] <= 0.50?\n",
      "                                    Y Decision: X['see_the'] <= 0.50?\n",
      "                                      Y Leaf: p(y=1 | this leaf) = 0.000 (66 total training examples)\n",
      "                                      N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                    N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.400 (5 total training examples)\n",
      "                                N Decision: X['chanc'] <= 0.50?\n",
      "                                  Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                                  N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "                              N Leaf: p(y=1 | this leaf) = 0.600 (5 total training examples)\n",
      "                            N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                          N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                        N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "                      N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                    N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "            N Decision: X['part'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "          N Decision: X['move'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (8 total training examples)\n",
      "    N Decision: X['movie'] <= 0.50?\n",
      "      Y Decision: X['learn'] <= 0.50?\n",
      "        Y Decision: X['man'] <= 0.50?\n",
      "          Y Decision: X['yesterday'] <= 0.50?\n",
      "            Y Decision: X['say_this'] <= 0.50?\n",
      "              Y Decision: X['pretti'] <= 0.50?\n",
      "                Y Decision: X['past'] <= 0.50?\n",
      "                  Y Leaf: p(y=1 | this leaf) = 0.000 (57 total training examples)\n",
      "                  N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.500 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.667 (3 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 0.800 (5 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "      N Decision: X['the_dvd'] <= 0.50?\n",
      "        Y Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 0.333 (3 total training examples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_sklearn_tree(best_tree, feature_names=vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Max_depth and min_sample_leaf  is 32 , 3 repectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A: Train a random forest with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_features='sqrt',\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the forest\n",
    "\n",
    "**TODO Train on the training set** in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, random_state=101)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_forest.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B & Table 2: Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2\n",
    "**Sample Output** (Feel free to print all words and organize them in any software)\n",
    "\n",
    "|**Important Words**|**Unimportant Words**|\n",
    "|:-:|:-:|\n",
    "|I1 |  U1  |\n",
    "|I2 |  U2  |\n",
    "|I3 |  U3  |\n",
    "|I4 |  U4  |\n",
    "|I5 |  U5  |\n",
    "|I6 |  U6  |\n",
    "|I7 |  U7  |\n",
    "|I8 |  U8  |\n",
    "|I9 |  U9  |\n",
    "|I0 |  U0  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature  importance\n",
      "113      return    0.032990\n",
      "100       excel    0.029485\n",
      "1         great    0.028984\n",
      "283       worst    0.028407\n",
      "130        poor    0.026748\n",
      "68   disappoint    0.024952\n",
      "525  your_money    0.018002\n",
      "167      i_love    0.017955\n",
      "78     the_best    0.017662\n",
      "4         don't    0.017654\n"
     ]
    }
   ],
   "source": [
    "importances = simple_forest.feature_importances_\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'feature': vocab_list,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort by importance, highest first\n",
    "feature_imp_df = feature_imp_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# --- 1. Get Top 10 Important Words ---\n",
    "top_10_words = feature_imp_df.head(10)\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Important Words Unimportant Words\n",
      "0          return           man_and\n",
      "1           excel           type_of\n",
      "2           great             as_my\n",
      "3           worst            to_use\n",
      "4            poor          may_have\n",
      "5      disappoint        the_viewer\n",
      "6      your_money        the_extras\n",
      "7          i_love           need_to\n",
      "8        the_best        reviews_of\n",
      "9           don't             death\n"
     ]
    }
   ],
   "source": [
    "near_zero_words_df = feature_imp_df[feature_imp_df['importance'] < 0.00001]\n",
    "\n",
    "\n",
    "num_eligible = near_zero_words_df.shape[0]\n",
    "\n",
    "random_10_near_zero = near_zero_words_df.sample(10, random_state=101)\n",
    "\n",
    "# Reset indices to align them for the table\n",
    "top_10_words = top_10_words.reset_index(drop=True)\n",
    "random_10_near_zero = random_10_near_zero.reset_index(drop=True)\n",
    "\n",
    "table2_df = pd.DataFrame({\n",
    "    'Important Words': top_10_words['feature'],\n",
    "    'Unimportant Words': random_10_near_zero['feature']\n",
    "})\n",
    "\n",
    "print(table2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C: Best Random Forest via grid search\n",
    "\n",
    "\n",
    "\n",
    "This block might take 2-10 minutes. \n",
    "\n",
    "If yours runs significantly longer, try this out on Google Colab instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_param_grid = {\n",
    "    'max_features': [3, 10, 33, 100, 333],\n",
    "    'max_depth': [16, 32],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [100],\n",
    "    'random_state': [101]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV object for Random Forest created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (No need to import sklearn.model; GridSearchCV was already imported earlier)\n",
    "base_forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "# Use the GridSearchCV symbol already imported earlier\n",
    "searcher_rf = GridSearchCV(\n",
    "    estimator=base_forest,\n",
    "    param_grid=randomforest_param_grid,\n",
    "    scoring='balanced_accuracy',  # Use balanced_accuracy\n",
    "    cv=my_split,               # Use our custom train/valid split\n",
    "    return_train_score=True,\n",
    "    refit=False,                  # As specified in the instructions\n",
    "    verbose=2                     # (Optional: Shows progress, helpful!)\n",
    ")\n",
    "\n",
    "print(\"GridSearchCV object for Random Forest created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest Grid Search...\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END max_depth=16, max_features=3, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   1.2s\n",
      "[CV] END max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   1.5s\n",
      "[CV] END max_depth=16, max_features=33, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   4.1s\n",
      "[CV] END max_depth=16, max_features=100, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   9.2s\n",
      "[CV] END max_depth=16, max_features=333, min_samples_leaf=1, n_estimators=100, random_state=101; total time=  25.5s\n",
      "[CV] END max_depth=32, max_features=3, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   1.5s\n",
      "[CV] END max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   2.7s\n",
      "[CV] END max_depth=32, max_features=33, min_samples_leaf=1, n_estimators=100, random_state=101; total time=   6.2s\n",
      "[CV] END max_depth=32, max_features=100, min_samples_leaf=1, n_estimators=100, random_state=101; total time=  14.5s\n",
      "[CV] END max_depth=32, max_features=333, min_samples_leaf=1, n_estimators=100, random_state=101; total time=  39.5s\n",
      "... Grid Search complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Random Forest Grid Search...\")\n",
    "searcher_rf.fit(x_tr_va_NF, y_tr_va_N)\n",
    "print(\"... Grid Search complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Forest grid search:\n",
      "{'max_depth': 32, 'max_features': 33, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 101}\n",
      "\n",
      "\n",
      "Best 'max_features' value: 33\n",
      "Maximum possible value for 'max_features': 7729 (the total number of features)\n",
      "\n",
      "Top 5 results:\n",
      "  param_max_depth param_max_features param_min_samples_leaf   \n",
      "7              32                 33                      1  \\\n",
      "6              32                 10                      1   \n",
      "2              16                 33                      1   \n",
      "1              16                 10                      1   \n",
      "3              16                100                      1   \n",
      "\n",
      "  param_n_estimators param_random_state  mean_test_score  \n",
      "7                100                101         0.851204  \n",
      "6                100                101         0.843626  \n",
      "2                100                101         0.842439  \n",
      "1                100                101         0.840997  \n",
      "3                100                101         0.839402  \n"
     ]
    }
   ],
   "source": [
    "# --- Display search results ---\n",
    "print(\"Best parameters found by Random Forest grid search:\")\n",
    "print(searcher_rf.best_params_)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Answer Assignment Questions ---\n",
    "\n",
    "# 1. What is the value of max_features of your best forest?\n",
    "best_max_features = searcher_rf.best_params_['max_features']\n",
    "print(f\"Best 'max_features' value: {best_max_features}\")\n",
    "\n",
    "# 2. What is the maximum possible value for max_features?\n",
    "F = x_tr_NF.shape[1]\n",
    "print(f\"Maximum possible value for 'max_features': {F} (the total number of features)\")\n",
    "\n",
    "print(\"\\nTop 5 results:\")\n",
    "results_rf_df = pd.DataFrame(searcher_rf.cv_results_)\n",
    "rel_cols_rf = [c for c in results_rf_df.columns if 'param_' in c or 'mean_test_score' in c]\n",
    "print(results_rf_df[rel_cols_rf].sort_values('mean_test_score', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best max_features: 33.\n",
    "\n",
    "Maximum possible max_features: 7,729 (equal to the total number of features in the dataset).\n",
    "• It sets how many features are considered at each split.\n",
    "• Effect:\n",
    "\n",
    "Lower → more randomization → trees less correlated → lower variance, but higher bias.\n",
    "\n",
    "Higher → splits use more info → lower bias, but trees become more similar → less variance reduction.\n",
    "\n",
    "n_estimators tradeoff: More trees → better averaging → lower variance & more stable predictions, but higher compute/memory.\n",
    "• Generally no for standard Random Forests—the ensemble average converges and test error usually plateaus (or improves slightly). The main cost is computation; not classic overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best random forest using the best hyperparameters found in 2B \n",
    "\n",
    "This is necessary so you have the specific best performing forest in your workspace.\n",
    "\n",
    "Train *only* on training set (do not merge train and valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=32, max_features=33, random_state=101)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = sklearn.ensemble.RandomForestClassifier(criterion='gini', random_state=101)\n",
    "best_forest.set_params(**searcher_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=32, max_features=33, random_state=101)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3: Comparison of methods on the bag-of-words to sentiment classification task.\n",
    "\n",
    "Please report **balanced accuracy** on the train, valid, and test sets, to 3 digits of precision\n",
    "\n",
    "**Sample Output** (Feel free to print all values and organize them by hand)\n",
    "\n",
    "|**method**|**max depth**|**num trees**|**train BAcc**|**valid BAcc**|**test BAcc**|\n",
    "|:-|:-:|:-:|:-:|:-:|:-:|\n",
    "|simple Tree\t| 1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best Tree\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|simple RandomForest\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best RandomForest\t|1 | 1 | 0.123\t|0.456\t|0.890|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models and their names for the report\n",
    "models = {\n",
    "    \"simple Tree\": simple_tree,\n",
    "    \"best Tree\": best_tree,\n",
    "    \"simple RandomForest\": simple_forest,\n",
    "    \"best RandomForest\": best_forest\n",
    "}\n",
    "\n",
    "# Prepare lists to build the results DataFrame\n",
    "method_list = []\n",
    "max_depth_list = []\n",
    "num_trees_list = []\n",
    "train_bacc_list = []\n",
    "valid_bacc_list = []\n",
    "test_bacc_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Get predictions for all data splits\n",
    "    y_pred_train = model.predict(x_tr_NF)\n",
    "    y_pred_valid = model.predict(x_va_NF)\n",
    "    y_pred_test = model.predict(x_te_NF)\n",
    "\n",
    "    # Calculate balanced accuracy for each split\n",
    "    train_bacc = sklearn.metrics.balanced_accuracy_score(y_tr_N, y_pred_train)\n",
    "    valid_bacc = sklearn.metrics.balanced_accuracy_score(y_va_N, y_pred_valid)\n",
    "    test_bacc = sklearn.metrics.balanced_accuracy_score(y_te_N, y_pred_test)\n",
    "\n",
    "    # Store results\n",
    "    method_list.append(name)\n",
    "    train_bacc_list.append(round(train_bacc, 3))\n",
    "    valid_bacc_list.append(round(valid_bacc, 3))\n",
    "    test_bacc_list.append(round(test_bacc, 3))\n",
    "    \n",
    "    # Store model-specific parameters\n",
    "    max_depth_list.append(model.get_params()['max_depth'])\n",
    "    if 'RandomForest' in name:\n",
    "        num_trees_list.append(model.get_params()['n_estimators'])\n",
    "    else:\n",
    "        num_trees_list.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_trees</th>\n",
       "      <th>train_BAcc</th>\n",
       "      <th>valid_BAcc</th>\n",
       "      <th>test_BAcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small Tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best Tree</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simple RandomForest</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best RandomForest</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                method  max_depth  num_trees  train_BAcc  valid_BAcc   \n",
       "0           small Tree          3          1       0.646       0.645  \\\n",
       "1            best Tree         32          1       0.877       0.732   \n",
       "2  simple RandomForest          3        100       0.819       0.797   \n",
       "3    best RandomForest         32        100       0.964       0.851   \n",
       "\n",
       "   test_BAcc  \n",
       "0      0.646  \n",
       "1      0.749  \n",
       "2      0.778  \n",
       "3      0.837  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary_df = pd.DataFrame({\n",
    "    'method': method_list,\n",
    "    'max_depth': max_depth_list,\n",
    "    'num_trees': num_trees_list,\n",
    "    'train_BAcc': train_bacc_list,\n",
    "    'valid_BAcc': valid_bacc_list,\n",
    "    'test_BAcc': test_bacc_list\n",
    "})\n",
    "results_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Hyperparameter Tuning Matters:\n",
    "Tuning greatly improved performance — the Decision Tree’s test accuracy rose from 0.646 → 0.749, and the Random Forest’s from 0.778 → 0.837. Careful tuning clearly enhances model effectiveness.\n",
    "\n",
    "Ensemble Models Perform Best:\n",
    "The Random Forest consistently outperformed single trees; even the untuned version surpassed the tuned Decision Tree. Combining multiple trees helps reduce variance and improves robustness.\n",
    "\n",
    "Overfitting vs. Generalization:\n",
    "Deeper models achieved higher training accuracy (e.g., Random Forest: 0.964 train vs. 0.837 test), indicating mild overfitting. Still, they generalized better overall.\n",
    "\n",
    "I think the tuned Random Forest is the optimal choice, offering the best trade-off between accuracy and generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
